{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5caea0",
   "metadata": {},
   "source": [
    "# Plastic Type Classification using CNN\n",
    "## Deep Learning Model for 7 Plastic Types\n",
    "\n",
    "This notebook implements an optimized Convolutional Neural Network to classify:\n",
    "- HDPE (High-Density Polyethylene)\n",
    "- LDPA (Low-Density Polyethylene)\n",
    "- PET (Polyethylene Terephthalate)\n",
    "- PP (Polypropylene)\n",
    "- PS (Polystyrene)\n",
    "- PVC (Polyvinyl Chloride)\n",
    "- Other (Mixed plastics)\n",
    "\n",
    "### Optimizations for Best Accuracy:\n",
    "- Aggressive data augmentation\n",
    "- Deep CNN with 4 convolutional blocks\n",
    "- Batch normalization and dropout\n",
    "- Learning rate scheduling\n",
    "- Early stopping with patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b39661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e35e99",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Setting up paths and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = Path.cwd()\n",
    "DATASET_DIR = BASE_DIR / \"dataset\" / \"Plastic Classification(1)\"\n",
    "OUTPUT_DIR = BASE_DIR / \"outputs\"\n",
    "\n",
    "# Create output directories\n",
    "(OUTPUT_DIR / \"models\").mkdir(parents=True, exist_ok=True)\n",
    "(OUTPUT_DIR / \"graphs\").mkdir(parents=True, exist_ok=True)\n",
    "(OUTPUT_DIR / \"predictions\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model hyperparameters (optimized for best accuracy)\n",
    "IMG_SIZE = 224  # Increased for better feature extraction\n",
    "BATCH_SIZE = 16  # Smaller batch for better generalization\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "CLASS_NAMES = ['HDPE', 'LDPA', 'Other', 'PET', 'PP', 'PS', 'PVC']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Max Epochs: {EPOCHS}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b75f6b",
   "metadata": {},
   "source": [
    "## Data Loading and Augmentation\n",
    "Using aggressive augmentation for maximum generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggressive data augmentation for maximum generalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DATASET_DIR / 'train',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_gen = val_test_datagen.flow_from_directory(\n",
    "    DATASET_DIR / 'validation',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = val_test_datagen.flow_from_directory(\n",
    "    DATASET_DIR / 'test',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")\n",
    "print(f\"Test samples: {test_gen.samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a58d23",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "Building optimized CNN with 4 convolutional blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # Input\n",
    "    layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    \n",
    "    # Block 1\n",
    "    layers.Conv2D(32, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(32, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Block 2\n",
    "    layers.Conv2D(64, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(64, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Block 3\n",
    "    layers.Conv2D(128, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(128, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Block 4\n",
    "    layers.Conv2D(256, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(256, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Dense layers\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acfd64c",
   "metadata": {},
   "source": [
    "## Compile Model\n",
    "Using Adam optimizer with optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e323e",
   "metadata": {},
   "source": [
    "## Setup Callbacks\n",
    "Early stopping, model checkpointing, and learning rate reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a439d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        OUTPUT_DIR / 'models' / 'best_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db102e",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "This may take 30-60 minutes depending on hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "training_time = datetime.now() - start_time\n",
    "\n",
    "print(f\"\\nTraining completed in {training_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff11a5cb",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e33ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_prec, test_rec = model.evaluate(test_gen, verbose=0)\n",
    "f1_score = 2 * (test_prec * test_rec) / (test_prec + test_rec) if (test_prec + test_rec) > 0 else 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Test Accuracy:  {test_acc*100:.2f}%\")\n",
    "print(f\"Test Precision: {test_prec:.4f}\")\n",
    "print(f\"Test Recall:    {test_rec:.4f}\")\n",
    "print(f\"Test F1-Score:  {f1_score:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd581e91",
   "metadata": {},
   "source": [
    "## Generate Predictions for Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen.reset()\n",
    "predictions = model.predict(test_gen, verbose=0)\n",
    "pred_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_gen.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fdfd2",
   "metadata": {},
   "source": [
    "## Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ce9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0, 0].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 1].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(history.history['precision'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_title('Precision', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(history.history['recall'], label='Train', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_title('Recall', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'graphs' / 'training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Saved: training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f7190",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0132cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_classes, pred_classes)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'graphs' / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Saved: confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed377f",
   "metadata": {},
   "source": [
    "## Sample Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aed5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen.reset()\n",
    "x_batch, y_batch = next(test_gen)\n",
    "pred_batch = model.predict(x_batch, verbose=0)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(16):\n",
    "    if i < len(x_batch):\n",
    "        axes[i].imshow(x_batch[i])\n",
    "        true_label = CLASS_NAMES[np.argmax(y_batch[i])]\n",
    "        pred_label = CLASS_NAMES[np.argmax(pred_batch[i])]\n",
    "        confidence = np.max(pred_batch[i]) * 100\n",
    "        \n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)',\n",
    "                         fontsize=10, color=color, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    else:\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Test Predictions', fontsize=18, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'predictions' / 'sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Saved: sample_predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142e9e7",
   "metadata": {},
   "source": [
    "## Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa06630",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(true_classes, pred_classes, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd50c6c",
   "metadata": {},
   "source": [
    "## Save Training Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310621de",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info = {\n",
    "    'model_config': {\n",
    "        'image_size': IMG_SIZE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'total_parameters': int(model.count_params())\n",
    "    },\n",
    "    'dataset': {\n",
    "        'train_samples': int(train_gen.samples),\n",
    "        'val_samples': int(val_gen.samples),\n",
    "        'test_samples': int(test_gen.samples),\n",
    "        'num_classes': 7,\n",
    "        'class_names': CLASS_NAMES\n",
    "    },\n",
    "    'results': {\n",
    "        'train_accuracy': float(history.history['accuracy'][-1]),\n",
    "        'val_accuracy': float(history.history['val_accuracy'][-1]),\n",
    "        'test_accuracy': float(test_acc),\n",
    "        'test_precision': float(test_prec),\n",
    "        'test_recall': float(test_rec),\n",
    "        'test_f1_score': float(f1_score),\n",
    "        'best_val_accuracy': float(max(history.history['val_accuracy']))\n",
    "    },\n",
    "    'training_time': str(training_time),\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / 'models' / 'training_info.json', 'w') as f:\n",
    "    json.dump(training_info, f, indent=4)\n",
    "\n",
    "print(\"✓ Training info saved: training_info.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a61da",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384da580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(OUTPUT_DIR / 'models' / 'plastic_classifier_final.keras')\n",
    "print(\"✓ Model saved: plastic_classifier_final.keras\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"Best Validation Accuracy: {max(history.history['val_accuracy'])*100:.2f}%\")\n",
    "print(f\"\\nAll outputs saved in: {OUTPUT_DIR}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  • outputs/models/best_model.keras\")\n",
    "print(\"  • outputs/models/plastic_classifier_final.keras\")\n",
    "print(\"  • outputs/models/training_info.json\")\n",
    "print(\"  • outputs/graphs/training_history.png\")\n",
    "print(\"  • outputs/graphs/confusion_matrix.png\")\n",
    "print(\"  • outputs/predictions/sample_predictions.png\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
